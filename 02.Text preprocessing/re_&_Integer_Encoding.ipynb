{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 정규 표현식을 이용한 토큰화"
      ],
      "metadata": {
        "id": "cDkAerRJYB5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMsFjZrwY4r9",
        "outputId": "876c7d4e-5e22-457e-9cec-f78ddca51440"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnqs7NW3G7n1",
        "outputId": "3b6c3307-d351-4156-8844-f6980a768746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
            "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
            "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "text = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery goes for a pastry shop\"\n",
        "\n",
        "tokenizer1 = RegexpTokenizer('[\\w]+')\n",
        "tokenizer2 = RegexpTokenizer('\\s+', gaps=True) # gaps=True : 해당 정규 표현식을 토큰으로 나누기 위한 기준을 사용한다\n",
        "tokenizer3 = RegexpTokenizer('\\s+') # 기재하지 않으면 토큰화 결과는 공백들만 나옴\n",
        "\n",
        "print(tokenizer1.tokenize(text))\n",
        "print(tokenizer2.tokenize(text))\n",
        "print(tokenizer3.tokenize(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정수 인코딩\n",
        "\n",
        "1. 각 단어를 고유한 정수에 맵핑시키는 전처리 작업 필요\n",
        "  - 단어를 빈도수 순으로 정렬한 단어 집합(vocabulary)를 만들고, 높은 순서대로 낮은 숫자부터 정수를 부여"
      ],
      "metadata": {
        "id": "5L40xJkzZn3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "0J4FsyncZJh6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = 'A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.'"
      ],
      "metadata": {
        "id": "DDYyGmKvad2q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 문장 토큰화\n",
        "sentences = sent_tokenize(raw_text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6KJyJs3aiCz",
        "outputId": "294bcfe4-4b93-4e3f-9e8c-0701b123a24e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "vocab = {}\n",
        "preprocessed_sentences = []\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for sentence in sentences:\n",
        "  # 단어 토큰화\n",
        "  tokenized_sentence = word_tokenize(sentence)\n",
        "  result = []\n",
        "\n",
        "  for word in tokenized_sentence:\n",
        "    word = word.lower()\n",
        "    if word not in stop_words:\n",
        "      if len(word) > 2:\n",
        "        result.append(word)\n",
        "        if word not in vocab:\n",
        "          vocab[word] = 0\n",
        "        vocab[word] += 1\n",
        "  preprocessed_sentences.append(result)\n",
        "print(preprocessed_sentences)\n",
        "print('단어 집합 : ', vocab)\n",
        "# 특정 단어 빈도수 출력\n",
        "print(vocab['barber'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRj4zMLWarfx",
        "outputId": "7829c807-f95a-4f43-bd3f-6de88c4da525"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
            "단어 집합 :  {'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n",
            "8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)\n",
        "print(vocab_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxI3yt93cuay",
        "outputId": "607c8da3-2b23-4c88-94ad-ebba5a1b099b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도수가 높을수록 낮은 정수 부여\n",
        "word_to_index = {}\n",
        "i = 0\n",
        "\n",
        "for (word, frequency) in vocab_sorted:\n",
        "  if frequency > 1:\n",
        "    i = i + 1\n",
        "    word_to_index[word] = i\n",
        "\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uNm3BQLdIbp",
        "outputId": "630b0ec8-19a0-43f6-8af4-2c0fc58d7ceb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 5개 단어만 사용\n",
        "vocab_size = 5\n",
        "\n",
        "words_frequency = [word for word, index in word_to_index.items() if index >= vocab_size + 1]\n",
        "\n",
        "for w in words_frequency:\n",
        "  del word_to_index[w]\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqp4RX0vdspA",
        "outputId": "ce4cbf11-4b65-4a65-ab27-b556b2f1ee4b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['OOV'] = len(word_to_index) + 1\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1HCUPr1gA5O",
        "outputId": "0ca1de53-f213-4c59-9173-06a3c5303671"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'OOV': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sentences = []\n",
        "\n",
        "for sentence in preprocessed_sentences:\n",
        "  encoded_sentence = []\n",
        "  for word in sentence:\n",
        "    try:\n",
        "      # 단어 집합에 있는 단어라면 해당 단어의 정수를 리턴\n",
        "      encoded_sentence.append(word_to_index[word])\n",
        "    except KeyError:\n",
        "      # 단어 집합에 없는 단어라면 'OOV'의 정수를 리턴\n",
        "      encoded_sentence.append(word_to_index['OOV'])\n",
        "  encoded_sentences.append(encoded_sentence)\n",
        "print(encoded_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT8xyx2pgnJf",
        "outputId": "efd41ed9-4f51-4c32-f502-2b4fe5fa5d32"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Counter 사용"
      ],
      "metadata": {
        "id": "Tw0CXB7qhS0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "tcVTTFu6hOKE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zqdYhKyhXjU",
        "outputId": "43ff2b92-6bb3-4336-aeb1-51355239d4cb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words_list = sum(preprocessed_sentences, [])\n",
        "print(all_words_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wKqxSLnhaSG",
        "outputId": "91bb88bb-c07f-48f0-81c5-eecd5e9ddcaf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이썬 Counter 모듈 이용\n",
        "vocab = Counter(all_words_list)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCBTd7kJhrPg",
        "outputId": "451e2c67-0181-4537-999f-349fffee01c4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab['barber'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCRHRWOmhxzf",
        "outputId": "32aae040-ac79-4d58-b887-b2ac424161e1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voacb_size = 5\n",
        "vocab = vocab.most_common(vocab_size) # 빈도수가 높은 상위 5개 단어만 저장\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0R9jNBwh6VP",
        "outputId": "9579d9ff-43d8-41ed-ab86-8ebc9cfe6ade"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인덱스 부여\n",
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab:\n",
        "  i = i + 1\n",
        "  word_to_index[word] = i\n",
        "\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg9yleGMiGdn",
        "outputId": "f094bdde-4083-4dd2-ed80-193fc3385aa8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. NLTK의 FreqDist 사용"
      ],
      "metadata": {
        "id": "ASb_lEyoiggJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "uG_7my-XifFC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = FreqDist(np.hstack(preprocessed_sentences))\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS_oGVHXioZX",
        "outputId": "08644502-d445-46df-baff-9fe52475f4a2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe3Gnb3Hiw0E",
        "outputId": "41535688-9c19-4870-cbf2-43be0b1ec889"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb0ZXiFQiys_",
        "outputId": "ebb5ebca-118d-4104-f6e9-735a4127f77e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 케라스 텍스트 전처리"
      ],
      "metadata": {
        "id": "IE3deI2CjUr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "xGyIPYfUjGaO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
      ],
      "metadata": {
        "id": "Syp4m5C5jc59"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "# 빈도수를 기준으로 단어 집합 생성\n",
        "# 텍스트로부터 단어 빈도수가 높은 순으로 낮은 정수 인덱스 부여 -> 정수 인코딩 작업\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)"
      ],
      "metadata": {
        "id": "_hDC7oRcjhMd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 부여된 인덱스 확인\n",
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M07VZG4Bjq4L",
        "outputId": "98d3e4c9-d0e6-4754-b2f6-4fdd46206731"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 단어 빈도수 확인\n",
        "print(tokenizer.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6BZrs49j1o5",
        "outputId": "f0e37e31-9b4a-462c-dc6c-45c5f40aec3e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력으로 들어온 코퍼스에 대해 각 단어를 이미 정해진 인덱스로 변환\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL48erGNkAH0",
        "outputId": "625ac116-64b5-45f3-bf49-ce16b826e5a7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 5개 사용\n",
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 1) # num_words는 0부터 카운트함\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)"
      ],
      "metadata": {
        "id": "wgiYqp6-kLHM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NxxVluBkoNU",
        "outputId": "f3db213b-b064-400e-c6ad-0aef9209b290"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB779TFHkt_V",
        "outputId": "567da1ad-2782-44b2-e8d9-ab9d9915ad1b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 5개 사용 (num_words)의 적용은 texts_to_sequences를 사용할 때 적용됨\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwwYCeCckyLF",
        "outputId": "16ae837e-1c61-4437-dfba-0bea3466afd6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word_index와 word_counts에도 지정된 num_words만큼만 남기고 싶을 경우\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)\n",
        "\n",
        "vocab_size = 5\n",
        "words_frequency = [word for word, index in tokenizer.word_index.items() if index >= vocab_size + 1]\n",
        "\n",
        "for word in words_frequency:\n",
        "  del tokenizer.word_index[word] # 인덱스 정보 삭제\n",
        "  del tokenizer.word_counts[word] # 카운트 정보 삭제\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaF81d1ik98z",
        "outputId": "d8acb5c1-8f5e-4e82-e65b-e112fb68df5e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
            "OrderedDict([('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4)])\n",
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 케라스 토크나이저는 OOV에 대해서는 단어를 정수로 바꾸는 과정에서 아예 단어를 제거함\n",
        "# OOV로 간주하여 보존하고 싶다면 Tokenizer의 인자 oov_token을 사용\n",
        "\n",
        "vocab_size = 5\n",
        "\n",
        "# 0, OOV 고려 (vocab_size)\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)"
      ],
      "metadata": {
        "id": "OUeftKrImrF4"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 OOV의 인덱스 : {}'.format(tokenizer.word_index['OOV'])) # 기본적으로 1 사용\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJLDAyFpnJY1",
        "outputId": "65167df9-b8e2-4b2d-a45d-da2f4befa8ce"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 OOV의 인덱스 : 1\n",
            "[[2, 6], [2, 1, 6], [2, 4, 6], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"
          ]
        }
      ]
    }
  ]
}